{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQc5WRA1FIVW"
      },
      "source": [
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOiu2xKPFIVZ"
      },
      "source": [
        "You need to work on a popular Fashion MNIST dataset for this HW. The dataset includes tiny images of fashion pieces. The objective is to create a set of supervised learning models that can predict the type of item based on its image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wkqX_c-FIVa"
      },
      "source": [
        "In order to load the dataset you need to have `tensorflow V2` on your computer. Use the following code to install the package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HSEdkAEvFIVb"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55lPOmYsFIVc"
      },
      "source": [
        "You can also check the version of it using the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HYuOLcGNFIVc",
        "outputId": "50092760-9bc3-462d-b58a-949b358abc32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'2.19.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux8qnETGFIVd"
      },
      "source": [
        "Now, it's time to load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x7f0t2NyFIVd",
        "outputId": "7b6a1376-031b-4fd4-b08e-5a4424dceafa"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUojzA5FIVe"
      },
      "source": [
        "As can be seen from the above code, the dataset was divided into train and test sets. Let's take a look at the X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U_tXHbdJFIVf",
        "outputId": "e0b21211-728e-4699-8ee3-702a105007e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyYJN2T2FIVf"
      },
      "source": [
        "As it is clear, the train dataset (`X_train`) contains 60,000 images of size 28 x 28. We can visualize one of the images using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "I72SQ3euFIVf",
        "outputId": "65f26f13-a8fb-4988-e7cf-7f55bb19c1e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sample_image = X_train[10]\n",
        "plt.imshow(sample_image, cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9A34OyTFIVf"
      },
      "source": [
        "The `y_train` also includes values between 0 and 9. Each represents a particular category. For example, we can check the value of `y_train` for the above image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0r0eoWtTFIVf",
        "outputId": "78c24911-c4b0-452c-dafd-5027aae0282a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEy_-XdJFIVg"
      },
      "source": [
        "The above code shows that the image belongs to category 0. To get the associated label with each category, you can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P_wPQbomFIVg",
        "outputId": "3c5fb2b0-b20a-4043-ed91-eb0079f4146f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-shirt/top\n"
          ]
        }
      ],
      "source": [
        "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "print(class_names[y_train[10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK1Jw3YMFIVg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KTn3QBoFIVg"
      },
      "source": [
        "<ul>\n",
        "    <li><b>Task1:</b> Use the train set to train various supervised models and evaluate their performance using the test set.</li>\n",
        "    <ul>\n",
        "        <li>Use different supervised learning models.</li>\n",
        "        <li>Use different metrics such as <b>accuracy</b>, <b>precision</b>, <b>AUC</b>, and ... in your model evaluation. </li>\n",
        "        <li>It is not enough to report the metrics. It is crucial that you interpret the metrics for each model and compare them across different models.</li>\n",
        "        <li> You may need to use the cross validation methods for hyperparameter selection.</li>\n",
        "        <li> Specify the model that outperforms the other models.</b>\n",
        "    </ul>\n",
        "    <li><b>Task2:</b> Use the best model to predict your own fashion pieces.</li>\n",
        "    <ul>\n",
        "        <li>Take a picture of ten fashion pieces of your own (take pictures in square format).</li>\n",
        "        <li>Resize images to the correct size (28,28).</li>\n",
        "        <li>Grayscale your images.</li>\n",
        "        <li>Visualize all the images side by side</li>\n",
        "        <li>Use the best model in Task 1 to predict the label of each of your own images.</li>\n",
        "        <li>How accurate is the final result?</li>\n",
        "    </ul>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPIgNZHUFIVg"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_hHhVPPFIVg"
      },
      "source": [
        "<ul>\n",
        "    <li>Make sure to put descriptive comments on your code</li>\n",
        "    <li>Use the markdown cell format in Jupiter to add your own interpretation to the result in each section.</li>\n",
        "    <li>Make sure to keep the output of your runs when you want to save the final version of the file.</li>\n",
        "    <li>The final work should be very well structured and should have a consistent flow of analysis.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EobFDbCUF6EH"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "otZU61lrFIVg",
        "outputId": "251f1111-5285-4962-e23f-a49548976285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.9.6 (default, Apr 30 2025, 02:07:17) \n",
            "[Clang 17.0.0 (clang-1700.0.13.5)]\n",
            "Platform: macOS-15.5-arm64-arm-64bit\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# %pip -q install -U tensorflow scikit-learn matplotlib seaborn pillow\n",
        "\n",
        "import sys, platform, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glefbJYdGFor"
      },
      "source": [
        "# 1. Load Fashion-MNIST and Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "E42ZugjKFIVg",
        "outputId": "85291b07-fb0e-46e6-bc77-523f5fcf5461"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Fashion-MNIST\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ZXRDK1ZNFIVg",
        "outputId": "3160fa03-9804-47fb-d18d-8755ee48bf63"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAEhCAYAAAAgbnIfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIQElEQVR4nO3dCZQVxb3H8QYVkIEBhnXYBUGQRVmURQ2CMQpCkMQlEqPGxGg2MXg0iXuMWYxB1GdifBq3KIYkoEZjFBVQBNxQGGQRQfZ12IZ9v+9UnzP3df2cWzXN7D3fzzkc79++t7tnprq663b9+18jlUqlAgAAAABAYtWs6B0AAAAAAJQtBn4AAAAAkHAM/AAAAAAg4Rj4AQAAAEDCMfADAAAAgIRj4AcAAAAACcfADwAAAAASjoEfAAAAACQcAz8AAAAASLgqP/C76667ggsvvLDIZdOnTw8aNmx41OuuUaNGMHfu3BLsHVA+fG39ueeeCwYOHFiu+wSUB9o+AFQ/9P1VfOB39dVXhwOtRYsWBdVB+/btgxdffLGidwMVrF69eul/xxxzTFC7du10PHTo0FLbzre//e1g1qxZzvecffbZwQMPPPCl/79///6wc928eXNw1VVXBTfccEOp7ReqL9o+cHRMezXHS/369YMGDRoE3bt3D2688cYgPz+/oncN8KLvr1iVYuC3c+fO4B//+EeQk5MT/PWvf63o3QHKza5du9L/zjrrrODee+9Nx//973/LZR9SqVRw+PDhjMunTZsW9OjRI2jSpEm57A+qB9o+cPTM8WKunbZv3x5eP61duzbo06dPsHHjxi+99+DBgxWyj0BR6PsrVqUY+E2cODHIysoK//h/+9vfrE7qqaeeCk499dTg17/+ddCsWbOgefPmRY7OC916663BKaecEqxfv/5Ly8x677jjjqBjx45B48aNg69//evBunXrnPv29ttvByeddFI48r/00kuDgoKC9LKPPvooOOOMM8JlJ598cvD8889bjWrcuHHhtsyA9vzzzw+++OKLcNnFF18crFq1KrjsssvCbziuu+662L8zVE9m6kKnTp3Cb3pbtWoVHhdRjz/+eNCmTZuwfd98881fOo6id5x/97vfBf379w/q1q0bXHLJJcGMGTOCn//851/61u3ll18Oj5WHHnoo3P6f//zn8D3dunULl5uLjx/84AdBbm5u+M+05927d4fLVqxYEd7Jf+yxx8Jtmv360Y9+FBw4cKAcfltIEto+8GWmjZnrj2effTbIzs4OrzsKp8A98sgjQdu2bdPT3d58883g9NNPD5eZNvzvf/87vZ433ngj6NmzZ3h8meusH/7wh+k7H2ZGlrkALry7+OGHH1bYz4vqh76/lKUqgf79+6d+9rOfpXbu3JnKyspKTZo0Kb3sySefTB177LGpP/7xj6kDBw6kpk2bFsZLly4Nl995552pkSNHpg4ePJi6+uqrU4MGDUpt3749XGbe26BBg/S6brrpptSQIUNS69atS+3fvz914403ps4666yM+2V+PX369EmtXbs2tW3bttS5556buuqqq8JlJm7cuHHqoYceCvdr+vTp4b6/++674fKnn3461bJly1ReXl5q7969qbFjx6ZOPvnkcD+Ndu3apV544YUy+o2iKjJtd/z48RmX79q1K2z7b7/9droNfvDBB+m2XrNmzfA4Mu1t4cKFqbp164b/v/A4OuWUU9LrMu2vc+fOqcWLF6cOHToUHg+Ztt+mTZvwfcaVV16ZGjNmjLX8u9/9bmrw4MGpzZs3p/Lz88P1XHPNNeGy5cuXh8fR0KFDw/01x5LZj7vuuqtUfmdIBto+UHyZ2uutt96aOv3009PHxLXXXpvavXt3+G/evHmphg0bpt56663U4cOHUzNmzEhlZ2en23dubm7qmWeeSR9vM2fODF8/+uijqd69e4dt+MiRI6nPPvsstWrVqnL+iZFU9P3lr8Lv+C1cuDB47733giuvvDIcTY8aNepL0z3NN01m/vpxxx0Xzsc1I+joQ1f27NkTfs7cjXv99dfDb6WUGceZEfv9998fjs5r1aoV3HPPPcHMmTOD1atXZ9w/8+1By5Ytw2/IzLcMEyZMCI4cORL85z//CZo2bRr89Kc/Dfdr0KBBwejRo4Onn346/Jy5c3n99deHt4rr1KkT/Pa3vw2388EHH5Tq7w/Vi2lrJg92x44dYZs87bTTrDZu2rRpb127dg2/5Z0zZ07GdZlvdM3dbDPH3hwPRTHHmVmfeV9RzLFgvg0z36KZb7XMsWra+jPPPBMuiz6EyeyvOZZ++ctfhscHEAdtH3Azd0O2bt0avjZt8Pe//314Z8P8e/TRR8NcpSFDhgQ1a9YMzjzzzGD48OHhNNHC42vp0qVhnqCZgVV4l9D8f3N3wxx75jjr3LlzeHcFKC/0/aWrwgd+ZpBnpmaaf4YZAJrBm5mvXshMO4gynZLpiKJ/JDNNwfySTZJoUUyCprkN+5WvfCX8Q5h/LVq0CP/wroFfu3btrNfmVq3pGNesWRMOQKM6dOgQ/n9Dl5v9Mn/8wuWAj5l2UJjwbDoV0+7N9IOXXnopPPGaE7eZh17ITPMxJ/hMx4kyU4B8Cqc7ZGKOBXNMRNu6OQ7M9CBzzGU6jqLHN6Bo+0B8pm2Z1BLDTIuLPvHQTD/7y1/+kr7+Mf/M8VSY7vLCCy8En376aXix26tXr/SA8Dvf+U44YDRT2cwFrnkdbd9AaaLvT/jAz+TcmRHwkiVLwkGY+WeewmMSLs3c3OIyI/w//elPwbnnnhssWLCgyPeYUblpHO+//36YDF34b+/evc7Hva5cuTL92uTlmYGiudPXunXrsCONMrH5/4YuN43EdLCFy803boCLSXIuTHi+5ZZbwv93zjnnBK+++mrYuZhcUVPKJPoNUxzaBotqkyYHJNoB6nvMsWCOiWhbN6/NFx3RpGg9jsw300AmtH0gnkOHDoUXx2ZWVFHt1Vw0jxkzxrr+MceXyQM0evfuHUyaNCk8vm6//fZwBpN5UMyxxx4bHoPz5s0L77qYNvyrX/2qQn5GJB99f9mr0NGH+eWaW7cff/xxeNfO/DOdi+l0nnjiifAWbnF973vfC2+7mgaSl5f3peXmD2e+sTJTRgvv8G3ZsiV8sIzLfffdFw7YTCdpHgzzrW99K1zXsGHDgk2bNoXTR02HaxJEza3fK664Ivzc5ZdfHjz88MPhVFbzLcBtt90W/tFNYnXhXcxly5bF/I2hOjMnYfOtrPk2y5yMzTdd5r+lRdukeUDS8uXLwwcYRd9jHlJUeGyaY8FcIJiHKpkpRuaYMp21+ZY42lnefffd4TFkjiVznJoveIDiou0DmS1evDicLWXSXcaOHVvke6699trgySefDO+WmC/XzXXJ7Nmzw8Gc+WLafAm/bdu2sO0W3ik0x9jUqVPDazNznWPuppgpcKV57AEu9P0JG/iZaZ7myZZdunRJ3/Ez/0xunPlFRW/nFoeZgmAGaubOX1GF180vfsCAAeEcdzMNwjz6eMqUKc51mgHc4MGDw9u05jMPPvhg+P8bNWoUfjNhnqRl7iaap/uYb87MbWjDDABN/p+ZQ29+JjOgNbePCxusaSRmYGg6WPO0H8DHfMNl2p/55tbksZq73P/6179K7e6xqVNjnvpm2qRpt6+88ko47cLMhS/0/e9/Pz2dyDwBzjD7ZKY8mCfLmSdenXjiiWEubdTIkSPDp2uZJ8L169cv/U0eUBy0fcBmnkRYWMfvG9/4RnidYZ40rqkxhcz0TfPkcfMltLljYb6INl+ymwGgYZ5fYNqvWae5djGxubYxF97mOs0cGyeccEK4vTvvvLOcf1pUV/T9pa+GecJLGawXQBU3YsSI8AsMM7XiaJnpD+ZiwXyTHM03ASoz2j4AVD8jqkHfT6IZgCKZwqqm/iRQ3dD2AaD6Oasa9P3c8QNQZir7N19AWaHtA0D1s6KS9/0M/AAAAAAg4ZjqCQAAAAAJx8APAAAAABKOgR8AAAAAJBxVOIFypmm1NWrUOOp1meK7UT/5yU+s+JJLLvlSLaeoWrVqWbEWRl2wYIEVm0KqUR06dLDim2++2YorY2Izqq5NmzZZ8VNPPWXF5jHcUaa2WWnS+rCmcHbUN7/5TSs+7rjjSnX7qD5MEemot99+24pfeuklKzY1xqJMMemo3r17O9vupEmTrNjUNosyxdu1xnGUqWUMJNG6deusuGXLlkFVxh0/AAAAAEg4Bn4AAAAAkHCUcwAq0VTOTz75xIonTpzonI5zzDHHWPGuXbuseO/evVa8devWoCQ6d+5sxTVr1nROH4pOtTvvvPOsZTfeeKMV9+jRo0T7huTR9vz3v//dih944AHn1OWmTZs6l+tUTN3e/v37rXj16tVWfOGFF1rxgAEDrPjiiy+2YiDqv//9b/r1+PHjrWXHH3+8FR84cMCK69SpY8U7duxwTtPfuHGjFbdv3945zT83N9eKGzRo4Dw21qxZY8Vf/epX068feughaxngMmTIECs29fCimjRpYsWPPfaYs23Hnco5ePBg53VU27Ztrfj11193TouubLjjBwAAAAAJx8APAAAAABKOgR8AAAAAJBw5fkA501yM6CPo582bZy3Tw7NevXrOPBDN09AcwEOHDllxQUGBFdetW9f5+bilJ/bt25dxnrzmrJx55plW/Oyzz8baFpLvn//8p7P9/+Y3v3Hmbmiek+YpafmR+vXrZ8xbMkaPHu3MEdQcQFRvy5Yts+K77ror/bpZs2bWMu0vjxw54syv1r5f81GV9uXa12dnZzvzYXV7jRs3zpjzp8fVuHHjnPuG6u3ss892Hjfab+uxotdJF110kfPa4vDhw878WW2/et7R67bKjjt+AAAAAJBwDPwAAAAAIOEY+AEAAABAwtmTtBMqbl21nTt3WvG7775rxUOHDo21vej8YZ0XH5cvJTNuDhbK36hRo6x41apV6dfNmzd3/j11LrrmZSh9v7YfzcvQ96u4KcHRufA6b15/thkzZljxokWLrLhr166xto3k8eXk/fjHP7bi//mf/7Hi2rVrx1pfnz59rPi73/2uFa9YscJZNxBw5ba52ovm9EXzpYvq+/Xa4oQTTnDW4dP1aX+sx4bS7R08eDBjLbVPP/3UWvbKK69Y8fDhw53bQvWSk5NjxcuXL3det2h94g0bNjjPA/MkJy8vL8+KGzVq5Gzbuv2qhjt+AAAAAJBwDPwAAAAAIOEY+AEAAABAwlWLHD+dK69z45cuXWrFjz/+uLNmR1ZWlhVr7tLpp59uxa68Ps2Z0n3V5b4cwbg5YCh7c+bMyZjTZzRp0iRjnT2l9WrWrl3rXK7tSduPthetDaW09p7WdtK6Z61bt864baXb1uOQ2k/Q9rV582YrbteunbPN6PGSn5+fMS9Jj82itqfHK2Vx4XLVVVdZ8fjx4zPm+2m+tz57QPteVatWLWdbV1q3T2u6+uj2tm/fXuR5wCCnDy4dO3a04vfee895Xau52z7tpZ/X5wu0bNnSeV21Z8+eoCrjjh8AAAAAJBwDPwAAAABIOAZ+AAAAAJBw1SLHz5f3NnXqVCt+4403rLhNmzbO+jY633fKlClWfM011xS7TpsvJ2/Xrl3OvKi48/JR9qZNm+ZsP9F6Svr31Bw9ncv+hz/8wYpzc3OdbXfdunXO9+v2NI9Ec/y0PX788cdW/NBDD2XMYdHaOPqzT5o0yYrJ8YOvf9yyZYtzuebstWjRwtmXa06gbl/7b+qowkXz/wcMGJB+/dJLL1nL+vXr58wn1baqtc805077X302ga5P+2etA7hp06bAJZoX9fvf/975XsBVs1evS7Sf1eduaNvXOn1KjwXN1dZjQfNhqxru+AEAAABAwjHwAwAAAICEY+AHAAAAAAlXLXL8dL6v+vDDD614xYoVzvnFGn/ta1+z4k8++cSKb7755vTrvn37Wst69OjhnNv8wQcfOPd14MCBGXMGipqXj/L3r3/9y5knFG1PWutO8y707xnNHy0qv1RrCF599dVW/Oijj1pxt27dMuYfFpUv26xZMyv+2c9+ZsV//vOfM86T13XrPP3Fixdb8ZIlS6y4c+fOVozk09wLX460ttdobbGy2L6vDicQdf3116dfP/DAA86alJqjp/2l5vf78pC0rer6dbkvz6mgoMCKhw4dWux9AaK07qOv/rA+e0CfXdCrVy8rzpb2qNvTa3xV1a+rueMHAAAAAAnHwA8AAAAAEi6RUz1903G0XMNHH33kvA28e/du55QzjU877TQrPvHEEzM+/n7WrFlWPHnyZOctbn0c9GOPPeac1jpkyBArRvmbN2+es8RCdNqClnpQOp1GnXfeeVZcr149K160aJEV//GPf7TiUaNGWfHLL7/snP6jUyi0nEO0/eq0VS3foLH+nmbPnm3FTPWsfrT/1ONFH8utU4K0jelyPXco37R/nb4MuPrPaP84c+ZMa9mtt97qXJdO7dTSO9FyCsbxxx/vbPv6fi0d5Jv+pstHjBjhfD+QiU7V1Lat/bRO8df3awrLQZm2rG1Xp3LqecZ3LFR23PEDAAAAgIRj4AcAAAAACcfADwAAAAASrkrm+PnyMHxuv/12K16/fr3z/ZqbpPOJdS78u+++mzGHUPMNe/fubcWdOnVybuvhhx+24i+++MKKJ02alPHnQPmYP3++8zHZrkfO+/IucnJynNtesGCBs21qW9c8Ej22fHPrNe/ONVd/3bp1zt+DHhuak/LOO+9Y8ZVXXuncNpKfI6XtUWPNxSjp+zXnWt+vxy/gaj+uvKYOHTpY8fLly535rPXr13fms+r7te1qPnh+fr5z3/Xzbdu2tWLgaOk1k5ZY69Kli7Nta7+tOX3Kd52jx5KvRFxlxx0/AAAAAEg4Bn4AAAAAkHAM/AAAAAAg4apkjp/mAsXVqFEjZ96T5hZpDQ+dL6y1pXS+cTRPS/dd8wG1rp/ONd64caMVn3/++VaMinfvvfc68/SysrKKXetO25LORdcalFu2bLHirVu3Otuutiddv27/wIEDVrx9+3YrnjhxohVv27Yt43Gln9Xluq9z5syxYlQ/mlektcw0x86Xs6d5pnHPNZpDC5QWbat6naF5R3qdojl/2ndr3+7LW/IdK82aNXMuB4qrRYsWzuW+HD5fnb0a0q9r7rjGel7RMURVwx0/AAAAAEg4Bn4AAAAAkHAM/AAAAAAg4apkjl9JaR6VLy9Ec490/nHjxo2dNUeic/F1brKvbpvO49d59mvWrLFiVLyBAwc68+iWLl1qxQUFBRnbptZ11PbQr18/Z/vQ92usbV3nyvvqmGn7zc7OtuLOnTunX+/evdu5bd1Wy5YtrfjCCy+0YlQ/vtwNbY/a3n19vY/mfmiOnx7rgEu0/WlbbdWqlRXn5eVl/GxRbVHXt2/fvljL9bpHcwI3b95sxa1btw6Ke9y46hkCStteXJrTV0NivW7S9qnXJnqdU9Vwxw8AAAAAEo6BHwAAAAAkHAM/AAAAAEi4KjnRWufb6lx3na+r9W/WrVvnnBuv9Wy0/o2+X+uyRXO2NAdQc7h03fXq1bPiHTt2WHGPHj2sWPOmtK5b3759rRhl70c/+pEzjta2Mz7//PP060ceecRaNn36dCvOyclxtoeGDRs621fcnKa4x57OxY8eCz179rSWTZgwoUT7guTTY0Vz9LQ9au5GSdu75kFprpK2d+3fo3lTJc1TQfXSvn17Z9vXvl2PlXbt2jnzlrTmq9Ym0/frdZEv/xuoqNrd+n7feaKG57yhy/Wav6rhjh8AAAAAJBwDPwAAAABIOAZ+AAAAAJBwVXJSts631bnvmuM3ceJEK16/fr0VN23a1FlLT9eneXWrVq2y4uOOO86K9+/fn3EevNZN021rrZwf//jHVjx37lxnDgoqH82lOP300zPmj06dOtXZ9qNtq6i2qe1Bc5aUzoXXWD+v29e2H81x0vqGgI8eDxqXNPcjbg6r0nNPgwYNrJi8PhytunXrOq9DlK9Gq6+On56X8vPznc9KUJpzCJQW7Zfjvt9XR/Kwp/6rxps2bQqqMu74AQAAAEDCMfADAAAAgIRj4AcAAAAACVclc/x0vq7Wl1Hdu3d35olonp0vZ1Dn92oeh9Zai+6vbktzsnSefZs2bZy1z2666SYr7t+/vxWj4ul8c20D0farOUj169eP1Tbj5jDFzZHyceVEaY1B5ZtnX9r7iqqfz13efDm2QByunGvNQ9JnEeh1j147+Ppf/bw+X6B58+bOnL+qXssM1SfHz1eXL+XJCdRnF6xYsSKoyrjjBwAAAAAJx8APAAAAABKOgR8AAAAAJFyp5fjpHFnNxdA5tvr+6BxaX60xnfvuM3ToUCuuV6+eFR9//PGx6tHoXHudD6z1clw5iPqz6M+uv8e8vDxn3ShUPjqfXOeLR3Xs2NGKs7OzS5Tf6pvLXtK8Od2+69jxtVXtI3x1q5B8vpw+X+0yn5J+3tdmo8t95zVUP672sWPHDivetm2b87ply5Ytsa5b9uzZY8UFBQWxzi3a9rWecUmu2YA4OX6+8YVvfTVi1gYnxw8AAAAAUKkx8AMAAACAhGPgBwAAAAAJd9QTr31zYMtyTvc777xjxZMmTbLid99914rr1q1rxY0bN3bWYtL5vvqz6Pr0d6Hri+b86bp9tXA0Z0rfP3nyZCseMWKEc32oeK68IM3b0JqTmj+q+YJaI9A3l12X++rfKK1hqXkj0fWRs4e4tL1r+/W1Z1fO3dHUBfQdTxpH+289VgBX3qfm5HXr1s2K27Zt6+x7tb1t3LjRmcPXrl075+c15zA3N9eK165dW+TPAcS1ZMkS53Ww9rO+6xTfdY7S5ToG2Lx5c1CVcccPAAAAABKOgR8AAAAAJBwDPwAAAABIuKNOxIubr7N161YrXrduXcY5vbpM89h0/q/mQel8X82L03o3LVu2dM5t17wpnSuv29e59gMHDky/3rlzp7VsxowZzjn/WvtMc7ree+89K0bl56qdp39/jePmOPm2Xdpz4111KH11zEpaUxDJ42t/cetS+tpvWdeXAopLrw20xqsvJ69+/fpWrNce27dvdz67QHMA9bpM6XXRpk2b0q+bNWvmPC6ocYmoRYsWWXHr1q2dbVOvuZXmcqc8/ba+X6/xN2zYYMWzZs3KeM1fGXG0AQAAAEDCMfADAAAAgIRj4AcAAAAACXfUOX6zZ8+24jvuuMOK8/PznfPJdU53dM53w4YNnfmEOndd59/q/F2tjabzbydOnGjFp512mrN+jc6lX7FiReCSl5eXfr1r1y7n3GXNR9S5y7t37461bVRtmlehx4avDlncHL24dH2agxpdfujQoVLdNpIvbp09n7g5sb4cQm3Tur+0eRQ3t2316tXWsoULF1pxhw4drHjbtm3OZxeceOKJzmuHL774woobNWrkvO7xqVevnhVPmDAh/fqGG26wlpHTB5e33nor1rMJfDmjcXPBj8j69P16bD3yyCNWTI4fAAAAAKBCMfADAAAAgIRj4AcAAAAACVfsHD/NXRgzZowzF+nYY491zrnVXLao/fv3O3P0NFYFBQVWvHLlSiv+xS9+4VyfztfNzc115vgNGTLEWW/n888/zzgPX3OiNCdE5xrr71Xr46Dyi1Ovzlcv88CBA7Hmtsetg+ZbrtvXfNvo+335TtTxg9L2p8eDr7366uj52lxJ615Gz0XZ2dnOzyL5XLltr7/+uhWffPLJVrxv3z4r1vak1zmtWrWy4sWLFzuPJX3eQPTZBEbz5s2tWK9lNEdw7dq1RV4DGZ06dbJiwFWfWq979Voibl0+H+3n9djT6xyt41fZcccPAAAAABKOgR8AAAAAJBwDPwAAAABIuGLn+D399NPO+eRaY0ZrxuzcudM5P9w1f1dz9nQuus5l37t3r3Nu+pVXXmnFL774ohWPGDHCipcvX+782ebMmWPF06ZNyzi/WOcGaz6j5kwpneus79daQG3atHGuD5Wbthede655Gr56Nr46ZJpzqu/XufK6XNunq5Yn4HPw4EFn+y5pHb6S0vau69fcECATzanr2bOns+3ruV+vJZQvx9p3rtBnG+i1huYcRmO9XiTHDy5an1rzR+P2677rFh899nSMsWHDhozHol7DVQbc8QMAAACAhGPgBwAAAAAJx8APAAAAABKu2Dl+Wi9O8+w0h0/ntbZt29b5/mgux44dO6xlOTk5VtyuXTvnunQuusaaFzVq1Cgr7tGjh3O+seYn6s/asGHDjHlTuu1atWqVal22JUuWWDE5flWbr46fKuncd1eOXlHr820v2vZ1Xrxv3YCvXlNJczfi8h0fmiPry0FE9RZ9foDWC9b80Hr16jmPDT1X+PpbX61lX85g3bp1nXlO0Wcv5OfnO9eF6m3btm1WrO1Fxx/aNrXtak6enhdqxryu1u197Wtfs+J//OMfGZ/7MXDgwKCy4Y4fAAAAACQcAz8AAAAASLhiT/XUqZ16q1SnFGrJA711q9MhmzZtWuTroqY06G1XXa5TJHbt2uWcHtS4cWMrXrhwoXOKhU5b1UfN6vajP49Or9CpQbrc99jYBg0aWPHcuXOt+JxzzrFiVC3aVn3iTnWLOxVN1++bUhGdfrRnz55Y2wJ85W18U3i0fZY219Tmos6DQKaSCNp29bpGjwW9ztBrBy2F4ptep5/Xc4/uzwknnGDFn3/+ecbPa0murVu3OtN5UL188sknzuW+62Jfv6/HygE5lnSatK9f/+yzz5zHyqJFi9KvmeoJAAAAACh3DPwAAAAAIOEY+AEAAABAwhU7x+/UU091lkB48sknrbhly5ZW3LFjR2eJhWgens6/1fm8Ondd557runW5zt/VxxLrY5V1/rDOB9b1a/5itNyEr/SDxlruQecaRx8HbTRv3tyKUfmU5JHzJc1Z8uX0+XIKfeUcdP+ic/Pj5isCei7Q9qe5H2VdPkHbt54LtH9etmxZ+nWvXr3KdN9Q9USvHbRt6XWJ5kjrdZBeK2jb1OsYLYOlx5Jeq6xdu9aK+/bta8XvvPNOxusovUbS/EJy/Kq3V155xYqbNGni7Fd9bVuf66HnhUPSHvX92dnZzmNDn7Wh+zN//vygMuOOHwAAAAAkHAM/AAAAAEg4Bn4AAAAAkHDFzvFTt9xyizMH8I9//KMzF01r9UVz23Ruu8591zp+vnozOr9X80R89XI0x9C3fhVdrj+bzrPX+jY6d1nnFvfs2dOKL7/8cue+oOL52qMrb0Pboo+vvo3OTdfl+vm4OX/R9cfNHwTWrVvnXO6rI6ntV9ugr835jgdt75oLorkqQNSWLVsyXnfoNdKnn37qPBdoTV9dn7ZNzWvS9+uzEvLy8qz4ggsucD6fILo+zenTayhUb9Fc6KKui/W611eLW9//8ssvW/Hw4cOt+Pjjj3fm02otb6XvX7BgQVCZcccPAAAAABKOgR8AAAAAJBwDPwAAAABIuGLn+PlyHYYNG+aMp06d6swRXLFiRfp1QUGBM49C5/dqPRtfbadmzZo58zxat27tnOuu833j1CfTnC1fPuO5555rxV27drXigQMHFnvbqPp8OXq+unq+2JfDpPTYcdUZpI4f4tK+V/t6bX/axlw5p0W9X2n9KH2/r35U27ZtnetH9Zafn5+x79S8pe3btzvbotZO1py9Ro0aWXFWVlaJasTqdZCuP3ps6rbWr19vxSeddFKsbSNZNOdu+vTpzn5c+13NsVO+HL1jZcyg/b7v/Xqe6tGjR1CZcccPAAAAABKOgR8AAAAAJBwDPwAAAABIuGLn+PnqefkMGTLEit97772M7128eHHGefBFzSVfs2aNFbdr186ZV9exY8di7jVQ+uLUq9O8jc8//9w511yPU40170OX675prNvTnCsX6vghrtNPP92KlyxZ4sx70lwL5au7F7cNaq6SHk/kLsFl9+7dGfP9tfad2rdvn/M6R2vl6XWU1gmM7ktR79dYa6+58sP1uNI6bajerrnmGiv+wQ9+4Oy3Nf9Vc7fjjl+aSL1VPa/osbVjxw5nPGbMmKAy444fAAAAACQcAz8AAAAASDgGfgAAAACQcMXO8StPXbp0ccaqe/fuZbxHQMXQueZaJ0xz7LZs2eLMq9NaTXFy9IrKidL1aw3MvXv3ZswJUb6agqh+NO/piiuusOJp06ZZ8ebNm515S5r35KvXpO1b23/79u2duey6/0CmnO0TTjjBmcPn6y+1lpnmu2rN3wkTJjiPjXPOOce5PY31XBVt+x06dLCWDR48WH4a4P/l5eVZcc+ePZ3vr127tnP5pk2bnMs3bNjgPPb0PKA5qq+//rrzOSOVDVdWAAAAAJBwDPwAAAAAIOEY+AEAAABAwtVIaYEMAGVKDzlX7bCbbrrJivfv32/FDRs2jJWzp3kZ9erVc+6Lr+6Z5uFpzlQ070Nrsg0fPty5r0CcY6UoW7dudeZyFBQUONffokULZxynbiB1KqGieXXat/pynjVnWvOKVq9ebcWaQwhUVTNmzLDiRYsWWfHUqVOtePz48Vacm5vrvM7SnMBLL73UiocNGxZUZdzxAwAAAICEY+AHAAAAAAnHwA8AAAAAEo4cPwAAAABIOO74AQAAAEDCMfADAAAAgIRj4AcAAAAACcfADwAAAAASjoEfAAAAACQcAz8AAAAASDgGfgAAAACQcAz8AAAAACDhGPgBAAAAQMIx8AMAAACAhGPgBwAAAAAJx8APAAAAABKOgR8AAAAAJBwDPwAAAABIOAZ+AAAAAJBwiR74nX322cEDDzwQvp4+fXrQsGHDit4loEq46667ggsvvLCidwOIjX4fKBnT95tzQHFwrkCSXFgN2n7NqnIir127dlCvXr0gJycnjOfMmVPRuwWUuc8++ywYMWJE0KRJkyA7Ozvo0qVLcO+991b0bgFljn4f+H+cC1Bd0far4cDPMH/kXbt2BevWrQt69eoVjBw5MqgKDh06FKRSqYreDVRRF1xwQXDKKacEq1atCrZt2xZMmjQp6NChQ1BV0P5REvT7QDLOBcDRou1X04FfoTp16gTf+973grVr1wY9evRIT+kx5s6dG9SoUaNY69m5c2fwgx/8IMjNzQ3/XXfddcHu3bvDZebi4u6777be/8Mf/jC49tprw9cHDx4M7rjjjqBjx45B48aNg69//evhhUkhsw8PP/xw0L179yArKyu8cAHi2rx5c7Bs2bKw3dWtWzc45phjgm7dugUXX3xxuLx9+/bBH/7wh6B///5B/fr1g0GDBgWrV69Of37Tpk3Bt7/97bB9t2zZMrjhhhuC/fv3h8tMmzTtvFmzZkGDBg2Cr3zlK8G8efMy7sutt94adrzr16+n/aPc0e+jOvOdC+6///6gU6dO4XnAtE/TDgutWLEibJt/+9vfghNPPDGc+nzVVVeF7bmQuZA2y8y54Jprrgm/uCgU91wBlCbafumrcgO/PXv2BI8//njQrl278OR7tMaMGRMsXbo0+PTTT4P58+cHixcvDn72s5+Fy77zne8Ezz77bPq9Bw4cCP7xj38EV1xxRfoieObMmcG7774bXgh37tw5+Na3vmWtf8KECcGUKVOCHTt2hBcBQFymfZ900knBd7/73bD9rVy58kvvMe30+eefD/Lz88N2dvvtt4f/39xtMBemLVq0CDtN08ZNh3XPPfeEy48cORKMHj06WL58ebBx48bwbsoll1zypbsUphM0F9ymvb/zzjvhxTLtH+WNfh/Vme9cYI6LqVOnhu3OHCc33XRT2Faj/vvf/waffPJJsHDhwuCtt94KnnvuufD/L1myJDwXjB8/PtiyZUvQp0+f4LXXXkt/rrjnCqAs0PbLQKoKGDRoUKpOnTqpBg0apJo3b54677zzUvPmzQv///jx49Pv++STT8xfw/pc4fJp06aFnzcOHz6cqlWrVuq9995Lv3fmzJmp2rVrh8v27duXatSoUWr27NnhssmTJ6c6duwYvj5y5EgqKysrNXfu3PRn9+7dm6pZs2Zq1apVYWz24YUXXijz3wuSb/369amxY8emTj755LCNde3aNTVlypRwWbt27VKPPPJI+r3PPvtsqnv37uHrDz74IJWTkxO250Lmcx06dChyO9u2bQvb7Zo1a8L4zjvvTJ177rmp4cOHp775zW+Gx4RB+0d5od8HincuUCNHjkzdc8894evly5eHbXPRokXp5d///vdTP/nJT8LXd999d2ro0KHW57t06RKeA4p7rjDbA8oKbb90VZk7fr/73e+C7du3Bxs2bAhH5D179jzqdZm7I+bbXDNVrpCZL2ymwZnbyuaBAmZU/8wzz4TLzH/Nt8GGWW6mBplbvua2sfln7qrUqlXLmmbXtm3bEv28gGHa1rhx44IFCxaE7Xbo0KHBqFGjgq1bt6aXFzJ3GMxUtsIpDuZ4MQ/FKGynF110UfitlbF3797gRz/6UXgMmGTpwmPBtO/oFLo33ngjfHKVOSYKl9P+UV7o9wH/ucDcwejdu3e6v3/11Vetvrzw80WdK8x0ZXPXJCoaF+dcAZQl2n7pqjIDv6KYp72ZKUCFzPSb4mjatGl4wjYXx4XMa3PiN08NMswJf+LEieEFh7lNXHgBYG47m3nG77//fnhBUvjPNJCBAwem11ezZpX+1aISMh2bGYSZC1Az9cClTZs24bz0aBstKChI5x2ZTtQ8IdFMWzNTJAqPhegUBtOe//SnPwXnnntu2OEatH9UNPp9VHfRc4GZsnzllVeG+d4mr9u0y2HDhhV7OprJ/9bpc+YhGoWKc64Aygttv+Sq9FnKjPInT54cXtCaP7r54xeHOTmbebsmZ8N8Y2Dm9t5yyy3hSb7wxH3GGWcEjRo1ChNB+/btm36CkFluHghw4403pr/pNZ83FwtAaTJPr7rtttvCPKTDhw+HF7smkdl0fOZxxi6nnXZaOPgznzffbpmOynRw5mLWMJ2YeWCGaeNmMGjaf1FMfp+563LOOecEeXl5tH9UOPp9VDeuc4H50sL07+aLPtNOzR0Pk2daXOYut8l7+s9//hPmdD/22GNh7lOh4p4rgLJA2y99VXrgZ5LyzcMmzAXukCFDgksvvbTYn33wwQfD27Ynn3xy+IQg81Qf05iizAXB66+/nk7uL2QuhAcMGBBu0zxJyCSExmlsQHGYuxPmKYbmGyzzRCkzjcwkLZvBm+/BEebJV6+88kr4+a5du4afN49ENg+2MMaOHRu+p3nz5uFTCE17zsRcBN93333hnT8z/ZP2j4pEv4/qxnUuMO3YfJlh2qW5M22+jDAP9iou8+AM89TD66+/Pvy8uat9/vnnp5fHOVcApY22X/pqmES/MlgvAAAAAKCSqNJ3/AAAAAAAfgz8AAAAACDhGPgBAAAAQMIx8AMAAACAhGPgBwAAAAAJx8APAAAAABKOgR8AAAAAJNyx5bUhLRdYo0aNo17Xpk2brHjq1KlW/Nhjj1lxw4YNrdgUtI6qXbu2FW/bts2KZ8+ebcX9+/e34t/+9rdWfPzxxwcV8XsBgMrOVTq2pP3f22+/bcUdO3a04tatW8da3/Lly634o48+suKLL7449j4CAFBRuOMHAAAAAAnHwA8AAAAAEq5GyjXvpgTiTmHcvHlz+vWDDz5oLXvzzTeteN++fVaclZVlxQcOHLDixYsXW/HOnTud+3LcccdZcatWraw4NzfXivfu3WvFOTk5Vjxo0KD065/+9KfWskaNGjn3BQCS5MiRI1Zcs2bm7x/XrFljxU888YQVjxs3zop37NgRlCXdVz1X3HvvvVY8ZsyYMvm9AABwNDizAAAAAEDCMfADAAAAgIRj4AcAAAAACVdhOX7Lli2z4uHDh6dft2jRwlpWp04dZ17FMccc4yzPoDl3u3btivV5zRnMz8+34kOHDlnx/v37rfjgwYPp13Xr1rWWXXvttVb8jW98w4oBoCqLk7vWq1cvK/7888+dfav2pxprPrjmVGupn/Xr1zvzt7VUj65fzy3Rc88555xjLZswYULgQs4fSvMazNeefM9h8F0qlqQUy6xZs6x44MCBVvzZZ59ZcefOnUtt20i+smy7cV1++eVWPHbsWCvu3bu385yn45OjwZkEAAAAABKOgR8AAAAAJBwDPwAAAABIuDLL8fO55JJLMtbx0zwMzaHT+bia86dz13VOrC/WnL6CgoKMOXuG71cYnVuv69b4pZdesuJ69eo51w0AlUncGq4DBgxIv/7oo4+sZc2bN3f2l7puPVfouWD37t3OfdUcvmOPPdbZ92v+uYruT/QcZ4wcOdKKX3zxxVL9vaJ68+X46bMNytL06dOteP78+c5c3ry8POfPMmXKlFLPe0LlEbevK+n7le/zeh7QMUi0fV900UXWsiVLlsQ6D+g5r1atWkFJcccPAAAAABKOgR8AAAAAJBwDPwAAAABIuHLL8dP6SJdeeqkVZ2dnZ8zL0DyLPXv2WPHhw4edsc5l11i3p7WZdHv6fl9dwWieni7bsmWLFV933XVWPHr0aCsGgKrshRdeyFi7tE2bNs68JM3R01wMjX19vS8PSulyjV3555oPuGnTJiuePHmyFQ8dOtS5L6heyjvH85lnnrHi/v37W/GMGTOs+KGHHrLili1bpl/PmzfPWYdPa5ddccUVVnzqqafG2nckS9ycPB0DqCPSb2tuuOZ6+2pgvvPOO1Y8atSojDl5Wjv2zTfftOJWrVqV+XHPHT8AAAAASDgGfgAAAACQcAz8AAAAACDhyi3Hb+HChVZ84YUXZpzXun//fmeOneZtaJ2LuHkcvlpQSt+v69ecxKgmTZpY8d69e6345JNPtuInnnjCuS8AUJF8OdW+/jPaJ2rfq/kQmuOn9ZR8fb9uW98fly/3I7o93+9lw4YNzrz4Fi1aWLH+rlznHVR9pZ3rs2jRImd7Gj9+vLOm8NatW515eoMGDcq4TOt1ahz9bFF5UieeeKL8NED5Wb16tRV37drViuvXr5/x/PjUU09Z8bBhw8o9l5c7fgAAAACQcAz8AAAAACDhGPgBAAAAQMKVW1JAXl6ecz55NL/BVytJ6yFF68UYHTt2tOL27dtbcd26dZ01O7Kyspx1+jQHcf78+Vb88ssvZ1z/9u3brWW7du1y5rAAQGXmy10bOXKkM28vmju0YsUK53t9NVSVr55TSbly+vR3o+cxPQ/peW369OlW/K1vfSvjupF8cXN99NkIs2bNcuaMNmjQwIqvvvpqZ86f1hsbO3ZsxjqVuu9dunSx4o8//tiK33jjDeexQY5f9eLLpfbZuHGjMz91i9TTnjNnjvPzOn7JycnJeGwVFBRYy/r27RtUNO74AQAAAEDCMfADAAAAgIQrt6meOk3lrLPOsuLnnnsu/frTTz+1lt1yyy3OaQJxpzxoCQWNdbrlvn37nFNBR48ebcW/+93vrPi0007L+Mhune7zxRdfZPw5AKCqmT17tnO5Tp2PM6VHp5D5psOVdvUi3/aj29OfRUtR6Hnmww8/dJ5Dy+Ix36i8dNqyb5qxppHUrl3bivU6S6cWP/roo1b82muvWfF5553n3N9mzZplXBadBlrUVLm1a9c6y1qdccYZVty9e3fnviDZbX/ZsmVWfMMNN1ixpljVj5RbMBYsWOBMH9NydGeffbZz2nP0nKbHna9cXFmXUzK44wcAAAAACcfADwAAAAASjoEfAAAAACRcueX43Xzzzc45uoMHD06/7tWrl7Vsx44dzhw/zdvIzs624saNGzsfEa6PBHflaRT1eFadK6+PGo7mL0YfXV7Uvul8YCBOjpK23bh5ITr//Nhjjy3Xxy67cqB0X8hxqhq0XM6BAweK3ca0vWtf7WsjvnIOmg+h7dd3vPnyKaLHkz6SXnMbNXd8woQJVjxu3DjntpBsvr7bd9xpW546daoVX3755Vb8l7/8JSgr+vh8vcbr06ePFdeqVct57Oj69LoKVZuvbI+WcHvqqafKtD00bdrUmZ8dzTm99NJLnfmDvms0Xa7HcdxrtHAbsT8BAAAAAKhSGPgBAAAAQMIx8AMAAACAhKuRKu3CRhm89dZbznjz5s3p11OmTLGWXXnllVY8aNAgZ87d0qVLnfVsfHlNmjei88t1Dm63bt2cNUL++c9/Zszha9SokRVPnjzZimfNmuWsdwO4lDRnz+fPf/6zFd9zzz1WvG7dulLdHiq/efPmWfGAAQOsuEGDBhlzGLQv19wMzZPT3ApfDqDm5PnyuTX2vd+V46rH3saNG61Yzw16Hlm9erUVA2VJ6xvrsRenZqa+96WXXnLmMWnOlj63Yf369c596927t3PfUL1ov3xY2psvh1BdcsklVjxp0qRi17h89dVXg9J0NPmt3PEDAAAAgIRj4AcAAAAACcfADwAAAAASrtzq+P3iF7+wNyz5DtHaFl27drWW/fvf/7biu+++27ktna+ruRO+PA/dN18O4O7du511Avv165d+3aJFi4z1C4uqAUhOH1x8OUhxc/q0dtjcuXMz5qsWlVuh9W0uu+yy9Ovnn38+1r5ovbc//OEPVnzbbbfFWh/Kh/aXml+hojnYmj+t7VvX7cux0+W+mkm+z/vq9rne78sr0X1Zs2aNc1tAHHHbvtLlvmPBJT8/34q1vrHvuNbnNpR27jqSfV10nCenz/dshCuuuMJ5XRTdvj5zRHNntd6mWrhwoRX/+Mc/tuJWrVpZ8bPPPhv4cMcPAAAAABKOgR8AAAAAJBwDPwAAAABIuHKbGD1q1ChnHb85c+akXw8dOtRa9vWvf92KN23aZMVt27Z1zmXXnDydY6vvVzq/t27dus75wjt37rTilStXpl+PHz8+4zJj+vTpVtyrVy9njOo9V91XS+nzzz93zkWfPXu2FWsNzQ4dOlhx69atnbXGVqxYUWo1a/7+979b8fvvv3/U60L5+fjjj525mq5aeFozVfMfNJ/al6uh29K8Jt9yPTf4asC6ziW6TM9Dmh+reU/a/qO544CPLydPl+ux57tO8p2rXMfx008/bcXDhw+34tGjRzuPDV+eFKoX33WRj54HlLZPrce9ffv2jDUodezTpk0b51hJbdu2zflchuLgjh8AAAAAJBwDPwAAAABIOAZ+AAAAAJBw5Zbjt2jRImeeXLS+Xf/+/a1lM2fOtOL58+c75/P66tH48qR0rnrcejhaqy86P/3UU0+1lp1wwgnO+b4nnXSSc19Q+Wj70/ahOU+a1xRnrnp0Lrlxyy23WPHEiROtOCsry4pzc3Ot+PTTT3fmx+7Zs8eKu3TpYsVr16614ttvvz3jvmuuru7r2LFjrXjx4sUZ84KNPn36ZNwWyo/2n75aeL48Pde69LP79u1zbsuXs+fr+5V+fv/+/VbcoEGDjLXHND9QfxZd1wMPPGDFcetionKLkyNXEXzHku/9UY0bN3Y+u+Cjjz6y4muvvdaKly1bZsUDBw507guSLe6xk/Kco+Iee3rdHn3Ox9atW61lI0aMcK6refPmzvOC1v7Wa7ji4I4fAAAAACQcAz8AAAAASDgGfgAAAACQcOWW46dzsnV++OrVqzPmyPnq5mlNF52vq3X4fDl6vrwPzXPS/dHcpej+a56H5kRpztaGDRucddVQ8XzzxZUrp09pzZdJkyY5a7jk5ORYcbdu3ZzHQkFBgRXv2LHDWR9JcwQ1F0OP3eeeey79+r777nOuu0ePHs4cJ83f0hqCqBy0P1ba/0b7Tz029Fjy5RUpX753XLo/ur/af0fPJZrb27BhQ+e+6rq1/SNZKltOX0nrAkbNnTvXik855RQrvuyyy6z4lVdeseLXX3/divVY0hwrVC9lXbfPZ968eVbcs2fP9Ov169c76xPrNdcdd9xhxTpmOPfcc4OS4o4fAAAAACQcAz8AAAAASDgGfgAAAACQcOWW46e5EXXq1MmYe6S5O5pTp/NxNTdC80B02746a/p+3/Z0vrkub9KkSZCJ1vjQ2k7r1q2zYnL8Kv/88ji5D8ZDDz2Ufv3II49YyzZu3OjMZejevbszh08/X9KalnosNG3a1Dlf3VVr6YUXXnDu2z333GPFf/rTn6y4Xbt2Vvzss89a8YknnuhcP8rGb3/7W2cOtKtenfaHWu8rbp290qbnFs3D02M/+rNpTUzNhdTznOa2v/jii1Wq7huSRdu+7zx37733Zjyur7vuOiv+29/+5jzuhw0bZsUrVqw46rx5VD++vvKQXHdr2/ZdF9WuXduKo2OYuOes3/zmN87xxMUXXxyUFHf8AAAAACDhGPgBAAAAQMIx8AMAAACAhCu3HD+dp+rKHWrUqJG1bO/evRnfW9S6fbkOcfOaXDkpRc0P1v1p3rx5xtxGnUus69q5c2fGnwMV4+OPP7biN954w4o/++wzZ/0tzduM/o21tlfr1q2ddfe0LepypXlD2t58OX2ap6TLtTZftL2///771rLc3Fwr3r17txW3atXKijt37uzMiXrssccy5pig/HzxxRfO/Adts9Ecac3b1L9xRef4Kd+5Inps67Gj5x1frnr79u2dnwfKkl6raJ7dXXfdlfHc0qxZM2c92k6dOlmxHit6ziSnr+pxPWvD16/rdUZJ6+4pXy1v1bdvXysePHiws+6kiz4jRPt9PSe6nhlSXNzxAwAAAICEY+AHAAAAAAnHwA8AAAAAEq7ccvyU5hZF59S2aNHCmefh48tT8uXk+WKd665zclU0x8VXU1DrsPnWjbL38MMPW/HkyZOdOaj6N9Z8BM1fyMrKyvjZXbt2Oduy5uxpjqDrOCsq/1C3r/lY2l71Z9f1ReevN2jQwHkcaW6v5kvptsh/rRzWrl3r/DtpToL259G/s7Zv7f98NVd9NTU1n8JHt6fr89Vziubcaj+g+d7anvVcsGrVqlj7jqpX+64890Xbrh4bem5ZtGiRFd90003OHOzVq1enX48bNy5WDtXcuXOdecMDBgxwfh6lz9fX+paXtN5xWarpyRn8xje+YcU9e/a04ieffDLjZ311w/UaTZ910KtXr6C0cccPAAAAABKOgR8AAAAAJBwDPwAAAABIuHLL8YtTc0hzfXQOrPLlfWiuhK/un29ffXl4uv1ozovmYGkOldKcKZS/73znO1Z82mmnWfHMmTOt+NNPP7XilStXOnN5tm3bljH/z9d2N23aZMWbN2+2Yl/OlOZ16PZ99XXq1auXMV9R85p0Tr8eZ5rz5Ms50XyqCy64wLmvKBszZsxwLvfl2UVz/LQNbN261Yo1T86XNxK3pmtJaZuMHg96LGr+rp7n9Hehxz4qP18ek6t/Le226Xs2gfavmrt7//33W/GQIUOsWOu0/vOf/zzqfdWf3bevKHtxc/riWLx4sRU/8cQTznzSpk2bOtfny6vbJ9fV2tfedtttVpyfn+98zkNJ8gd9dck7duzo/PzR/B244wcAAAAACcfADwAAAAASjoEfAAAAACRchdXxi0Pn4/pqKfnq8CnfnFjfHFzN69i+fXvGHL9OnTo569VoDosvxwplT/8G3bt3t+J+/fo5P695nMuXL7fipUuXpl+vWLHCWrZu3bpYdfd8c9sbN25sxfXr13cu15xUrcWnyzX3wpWLoblevrau9eA0n7C0c2JQPFpvUWn/qG00+nfXvlNze3w5r76+WmPdd18b1P3RNqfri+aO6LJobm9xflYkT1n2WXFrXKq77rrLilu2bGnFeXl5Vjxx4sSgtOhxrLnrep2E0ufL99e/kfZXmif3+OOPW7HW63ZdI7300ktW/Nlnn5XouR91JKcvWnOyqPzUV1991bk9rV17/PHHF/scpecBPU7PPPNM57bJ8QMAAAAAfAkDPwAAAABIOAZ+AAAAAJBw5ZZEoLlEWsPIlYen82c1V0LnqvvqZvjqkWjsqyPoy8uL/mxt27a1ln300UfOfBjN+0D50zy23bt3W/H69etj5Qnl5ORY8dlnn50xh8+XP+XLOdLjStcft66ffl6PY613E61ZqOvSn02Psz179jj7EM0paNeunRX36NHDilE2Bg0a5FyubdKVG+LLwfPlC+q2tE1pHM3FKKqN+mqf6fp0f6Pv15/bty1Ufb78m2hO68aNG53nleh5oizyB++8805n/6o5fS+88EKx1+27hvLVRtYcP5Q937WHz8cff2zF2r6j7VP78WbNmjnrFb/88stWPGLEiBIdC5dddpkVn3/++bFq6el5JI4NGzY4n10wcODAoLRxxw8AAAAAEo6BHwAAAAAkHAM/AAAAAEi4Msvx01whX15ddnZ2xnVpLoSvvpFuy5dLEbd2ky+n0JVn0r59e+e++fJAUPF0DrbGPpqzGv0ba9vSHDqtCehrH9p2dS69L6/Il0OoeXetWrXKeGxpnkfcfCpdrr93rTOF8vGf//wnVg60xtG80ObNmzvfq321r//UNhM3R9B3/PhyCqP1ovSzvvZNzl/V58stWrhwYcZaYnpNpDnPrhqpxbF27VornjVrljOfe8aMGUe9LV+er+/9q1atOupt4+i88847zr/BRRdd5KyNpzmqKloTuFGjRs6cOT3XjxkzJlaOnxo5cqQVL1iwwFk3sCwVFBSU6Lg+mlrf3PEDAAAAgIRj4AcAAAAACVdmUz31Vr1v+qVOEYsz3cw3bcBXrkFjXZ/Gvuk+OhU1+kj7Tp06xZqqdDS3cVG56TQG16OAdQoEUNm89tprzuXaH+p0y2j/+Mgjj1jLvv3tbzv7y3r16jn7T50qqst95xaln9fpcBpHp/Fo2YuVK1c6y8b46OPRdZosyr4cQ0k/XxaPai+ua665xoqXLFlixa+88kqpbStueo0eZ4sXLy61fUHxfPHFF1Z87bXXWvHtt9/u7It1KrEuj5aL0GnO+lnfNfjNN99sxd///vet+Oc//7kVT5s2zYq/+tWvWnHjxo2D8qJTYjV9xidun2Rwxw8AAAAAEo6BHwAAAAAkHAM/AAAAAEi4Msvx881D1Tm6rkexax6Gr+SB7xHccXMCdd/jzleP5nl069bNuW8ak+MHoDLTEiOao6CPoXf1v6NGjbLi66+/3oonTJiQMT/Q2Lp1qxXn5uY691Vp3659fzQvpahyK/r5fv36ZXwE+dtvv+3clq+cw7///W9nzhZK7mjyZ+J8Pnp+HzZsmDPP6Re/+IUVjx49Ota+3H333c7c3BtuuMGKe/ToEVQUvYbbtm1bhe1LdXXVVVdZ8f/+7/9mLEVS1N9I+/kWLVpk7Du3b99uLWvSpIkzd1qvi++77z5n3LRpU+dzFX71q18FLnHHEHHozx431/to9oU7fgAAAACQcAz8AAAAACDhGPgBAAAAQMJVWI6fztFt165dxs9q3Sedr6s5Jb7cCK0r5cuzU7rvmjei85Gjc5ld9QqL2vdDhw453w8AFUn7ds27i5uzEPX73//eGftoX6z75svn1ljrAmZnZwelRfdFc9fr1KljxS+//LIVk+NX+qZPn+78++u1R05OjhVnZWU5r2Wif1P9+y5dutSKx40b56w91qxZMyueMmWKFT/44INWfPbZZ5fo2CrL3Ee9BtPfG8pf+/btrfi9996z4rZt21rxgQMHnHVHo39jrfGn19S+9qL1jn3tpYXkG/ryWUuS66s/i+YXRp8BUpx6rHpO036jOLjjBwAAAAAJx8APAAAAABKOgR8AAAAAJFyZ5fhpvoKvHp3OlY+TQ6e1lbZs2eLM6Ytbh883/1zzPHbv3m3F69evzzgfV382zenTedIAUJn89a9/teLJkyc7+8OyrImktL89mnyI8sqZyc/Pd+ZG6nnvjDPOKMO9g7FixQpnvGnTJmcOqV6baC5S9FqkTZs21rLLL7/cinv27GnFb775phXPmjXLiufPn2/FZ555pjNnUPMX9dqkPPPsNA/qvPPOK7dto2i//OUvrfj555+34tWrVzuvq/UaP3rdrG1Lc+r0uljzn3Vbeo7R43KC1INVpXmO8o0vtF/35fj5nkFSHNzxAwAAAICEY+AHAAAAAAnHwA8AAAAAEq7McvwOHz7snD8eJ8/uoosusuIdO3Y46/rptn11/fT9vvxEne+rOYQNGjSw4r59+2bctuYA6L7qvgFAZaK5aCtXrrTigQMHOvvv0aNHl9q++Gqyauyrz+RbrucCjaPnDl3X+eefb8WPP/54xvqvxgUXXGDFP//5z537hpK76qqrSvR5fd7AmjVrrHjr1q0Zl+l1hx5XmtOnx9WwYcOcx5nmFKqKrJ2nOX7333+/Fd9+++3lvEfQWnfaPl977TUrvuOOO6z4ww8/dLbXsnTWWWdZ8eDBg8tt2778QD2OW7ZsWWY1BdP7VOI1AAAAAAAqNQZ+AAAAAJBwDPwAAAAAIOHKLMdv7969sXIttm/fXuz6IUmi83Xj/F4AoLJp27atsxap1lTS3CZXDcCsrKwS5dyVt2iOtuaCn3rqqVasyzXH7yc/+UmZ7CPKTuPGjZ0xilfjkrZf+WnOssZqyZIl6ddz5syxluXl5Vnx2rVrM+bGFnUd3apVKyv+y1/+4tyXlOc5HiXhy5W9+eabrfikk05yvl+fl3I0uOMHAAAAAAnHwA8AAAAAEo6BHwAAAAAkXJnl+OXk5Fhx586dnTVk+vXrl3Fdrhp/pVXXoqJobZ3ly5dbcZ8+fcp5jwDg6Gl/fd999znPDbm5uZWyllhpcJ2btP6s1i7Tn72i8xWBivLrX/+6oncBpSw6JtDxwWWXXVau+1KjDMcQvnV/9atfjbU+X13y4uBMAgAAAAAJx8APAAAAABKOgR8AAAAAJFyNlC+BDgAAAABQpXHHDwAAAAASjoEfAAAAACQcAz8AAAAASDgGfgAAAACQcAz8AAAAACDhGPgBAAAAQMIx8AMAAACAhGPgBwAAAAAJx8APAAAAAIJk+z+DkFGuVpkZAAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x300 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize a few samples\n",
        "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat',\n",
        "               'Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "for i in range(10):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(X_train[i], cmap='binary')\n",
        "    plt.title(class_names[y_train[i]], fontsize=9)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WlBR_kPGOtp"
      },
      "source": [
        "# 2. Preprocessing\n",
        "We’ll prepare two pipelines:\n",
        "\n",
        "- For classical ML (LogReg/SVM/RF): flatten 28x28 to 784 features; scale if needed.\n",
        "\n",
        "- For CNN: keep 28x28x1, normalize to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5sqzTRypFIVg"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "X_train_cnn = (X_train.astype(\"float32\") / 255.0)[..., np.newaxis]\n",
        "X_test_cnn  = (X_test.astype(\"float32\") / 255.0)[..., np.newaxis]\n",
        "\n",
        "# Flatten for classical ML\n",
        "X_train_flat = X_train.reshape(len(X_train), -1).astype(\"float32\")/255.0\n",
        "X_test_flat  = X_test.reshape(len(X_test), -1).astype(\"float32\")/255.0\n",
        "\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F7rqptQGWZU"
      },
      "source": [
        "# 3. Baselines and Classical Models (Task 1)\n",
        "We will evaluate:\n",
        "\n",
        "- Logistic Regression (multinomial)\n",
        "- Linear SVM and RBF SVM (using probabilities via probability=True)\n",
        "- Random Forest\n",
        "\n",
        "We’ll compute accuracy, macro-precision, and OvR ROC-AUC (requires predict_proba). For SVM linear we’ll do two runs: one with calibrated probs via probability=True (note the slower training) or use decision_function with OneVsRestClassifier+CalibratedClassifierCV if desired. To keep runtime sane, we’ll limit grid sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4-b604waFIVg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(clf, X_tr, y_tr, X_te, y_te, model_name):\n",
        "    y_proba = None\n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        y_proba = clf.predict_proba(X_te)\n",
        "    elif hasattr(clf, \"decision_function\"):\n",
        "        # Convert decision scores to probabilities via softmax-like normalization per class\n",
        "        # Note: not a calibrated probability; acceptable for a rough AUC comparison if needed\n",
        "        scores = clf.decision_function(X_te)\n",
        "        # If binary shape, convert to two-column\n",
        "        if scores.ndim == 1:\n",
        "            scores = np.vstack([-scores, scores]).T\n",
        "        # Min-max per row to 0..1\n",
        "        s_min = scores.min(axis=1, keepdims=True)\n",
        "        s_max = scores.max(axis=1, keepdims=True)\n",
        "        denom = np.where((s_max - s_min)==0, 1, (s_max - s_min))\n",
        "        y_proba = (scores - s_min) / denom\n",
        "\n",
        "    y_pred = clf.predict(X_te)\n",
        "\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    prec_macro = precision_score(y_te, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    auc_ovr = None\n",
        "    if y_proba is not None:\n",
        "        # One-vs-Rest multiclass AUC with macro averaging\n",
        "        y_true_bin = keras.utils.to_categorical(y_te, num_classes=num_classes)\n",
        "        try:\n",
        "            auc_ovr = roc_auc_score(y_true_bin, y_proba, average='macro', multi_class='ovr')\n",
        "        except Exception:\n",
        "            auc_ovr = None\n",
        "\n",
        "    print(f\"{model_name} — Accuracy: {acc:.4f} | Macro-Precision: {prec_macro:.4f} | OvR AUC: {auc_ovr if auc_ovr is not None else 'n/a'}\")\n",
        "    return {\"model\": model_name, \"acc\": acc, \"prec_macro\": prec_macro, \"auc_ovr\": auc_ovr}\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtSJfBXHGklY"
      },
      "source": [
        "## 3.1 Logistic Regression (with small grid search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I6rhAF47GmAC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .........................................clf__C=1.0; total time=  40.3s\n",
            "[CV] END .........................................clf__C=2.0; total time=  40.2s\n",
            "[CV] END .........................................clf__C=1.0; total time=  40.4s\n",
            "[CV] END .........................................clf__C=0.5; total time=  40.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .........................................clf__C=0.5; total time=  40.5s\n",
            "[CV] END .........................................clf__C=2.0; total time=  40.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR best params: {'clf__C': 1.0}\n",
            "LogisticRegression — Accuracy: 0.8459 | Macro-Precision: 0.8450 | OvR AUC: 0.9834649888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chhaviverma/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Use a smaller subset for grid search to speed up tuning\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(X_train_flat, y_train, train_size=8000, stratify=y_train, random_state=42)\n",
        "pipe_lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),  # with_mean=False safer for sparse-like; here dense but fine\n",
        "    (\"clf\", LogisticRegression(max_iter=200, solver='saga', tol=1e-3, n_jobs=-1))\n",
        "])\n",
        "\n",
        "param_lr = {\n",
        "    \"clf__C\": [1.0, 0.5, 2.0]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "grid_lr = GridSearchCV(pipe_lr, param_lr, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_lr.fit(X_train_sub, y_train_sub)\n",
        "best_lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    (\"clf\", LogisticRegression(max_iter=200, solver='saga', tol=1e-3, n_jobs=-1, C=grid_lr.best_params_[\"clf__C\"]))\n",
        "])\n",
        "print(\"training full dataset\")\n",
        "best_lr.fit(X_train_flat, y_train)\n",
        "print(\"LR best params:\", grid_lr.best_params_)\n",
        "\n",
        "res_lr = evaluate_model(best_lr, X_train_flat, y_train, X_test_flat, y_test, \"LogisticRegression\")\n",
        "results.append(res_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RzwAZJGoDA"
      },
      "source": [
        "## 3.2 Support Vector Machines\n",
        "Linear SVM (probability=True uses Platt scaling internally; slower):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gem-IcU5Guio"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "[CV] END .........................................clf__C=0.5; total time=  24.6s\n",
            "[CV] END .........................................clf__C=1.0; total time=  24.8s\n",
            "[CV] END .........................................clf__C=0.5; total time=  24.6s\n",
            "[CV] END .........................................clf__C=1.0; total time=  24.8s\n",
            "[CV] END .........................................clf__C=1.0; total time=  25.6s\n",
            "[CV] END .........................................clf__C=0.5; total time=  25.7s\n",
            "[CV] END .........................................clf__C=1.0; total time=  25.6s\n",
            "[CV] END .........................................clf__C=0.5; total time=  25.7s\n",
            "SVM-linear best params: {'clf__C': 0.5}\n",
            "SVM-linear best params: {'clf__C': 0.5}\n"
          ]
        }
      ],
      "source": [
        "# Use a smaller subset for grid search to speed up tuning (same as logreg)\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(X_train_flat, y_train, train_size=8000, stratify=y_train, random_state=42)\n",
        "pipe_svm_lin = Pipeline([\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    (\"clf\", SVC(kernel='linear', probability=True))\n",
        "])\n",
        "\n",
        "param_svm_lin = {\"clf__C\": [0.5, 1.0]}\n",
        "grid_svm_lin = GridSearchCV(pipe_svm_lin, param_svm_lin, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_svm_lin.fit(X_train_sub, y_train_sub)\n",
        "best_svm_lin = grid_svm_lin.best_estimator_\n",
        "print(\"SVM-linear best params:\", grid_svm_lin.best_params_)\n",
        "\n",
        "# Retrain best SVM-linear on full data for evaluation\n",
        "best_svm_lin.fit(X_train_flat, y_train)\n",
        "res_svm_lin = evaluate_model(best_svm_lin, X_train_flat, y_train, X_test_flat, y_test, \"SVM-Linear\")\n",
        "results.append(res_svm_lin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5b12bntGuEP"
      },
      "source": [
        "### RBF SVM:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jMJDLgrG0N7"
      },
      "outputs": [],
      "source": [
        "# Use a smaller subset for grid search to speed up tuning (same as logreg)\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(X_train_flat, y_train, train_size=8000, stratify=y_train, random_state=42)\n",
        "pipe_svm_rbf = Pipeline([\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    (\"clf\", SVC(kernel='rbf', probability=True))\n",
        "])\n",
        "\n",
        "param_svm_rbf = {\"clf__C\": [1.0], \"clf__gamma\": ['scale']}\n",
        "grid_svm_rbf = GridSearchCV(pipe_svm_rbf, param_svm_rbf, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_svm_rbf.fit(X_train_sub, y_train_sub)\n",
        "best_svm_rbf = grid_svm_rbf.best_estimator_\n",
        "print(\"SVM-RBF best params:\", grid_svm_rbf.best_params_)\n",
        "\n",
        "# Retrain best SVM-RBF on full data for evaluation\n",
        "best_svm_rbf.fit(X_train_flat, y_train)\n",
        "res_svm_rbf = evaluate_model(best_svm_rbf, X_train_flat, y_train, X_test_flat, y_test, \"SVM-RBF\")\n",
        "results.append(res_svm_rbf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl-wa-D1Gz5W"
      },
      "source": [
        "## 3.3 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbqh7AbyG5F5"
      },
      "outputs": [],
      "source": [
        "# Use a smaller subset for initial fitting to speed up tuning (same as logreg)\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(X_train_flat, y_train, train_size=8000, stratify=y_train, random_state=42)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300, max_depth=None, n_jobs=-1, random_state=42, class_weight=None\n",
        ")\n",
        "rf.fit(X_train_sub, y_train_sub)\n",
        "# Retrain on full data for evaluation\n",
        "rf.fit(X_train_flat, y_train)\n",
        "res_rf = evaluate_model(rf, X_train_flat, y_train, X_test_flat, y_test, \"RandomForest\")\n",
        "results.append(res_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klFLVHdoG7IG"
      },
      "source": [
        "## 3.4 Compare Classical Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IimFwb4qG7Ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results).sort_values(by=\"acc\", ascending=False)\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeSUH4YvG639"
      },
      "source": [
        "# add confusion matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R79L6mxAG6sQ"
      },
      "outputs": [],
      "source": [
        "best_name = df_results.iloc[0][\"model\"]\n",
        "best_clf = {\n",
        "    \"LogisticRegression\": best_lr,\n",
        "    \"SVM-Linear\": best_svm_lin,\n",
        "    \"SVM-RBF\": best_svm_rbf,\n",
        "    \"RandomForest\": rf\n",
        "}[best_name]\n",
        "\n",
        "y_pred_best = best_clf.predict(X_test_flat)\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(f\"Confusion Matrix — {best_name}\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "print(classification_report(y_test, y_pred_best, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLFgzGI4G5vB"
      },
      "source": [
        "# 4. CNN Model (Task 1, Deep Learning)\n",
        "A compact CNN often outperforms classical models on Fashion-MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUHqneQvG5kX"
      },
      "outputs": [],
      "source": [
        "def make_cnn():\n",
        "    inputs = keras.Input(shape=(28,28,1))\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn = make_cnn()\n",
        "history = cnn.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=8,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = cnn.evaluate(X_test_cnn, y_test, verbose=2)\n",
        "print(f\"CNN — Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_proba_cnn = cnn.predict(X_test_cnn, verbose=2)\n",
        "y_pred_cnn = np.argmax(y_proba_cnn, axis=1)\n",
        "\n",
        "prec_macro_cnn = precision_score(y_test, y_pred_cnn, average='macro', zero_division=0)\n",
        "y_true_bin = keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "auc_ovr_cnn = roc_auc_score(y_true_bin, y_proba_cnn, average='macro', multi_class='ovr')\n",
        "\n",
        "print(f\"CNN — Macro-Precision: {prec_macro_cnn:.4f} | OvR AUC: {auc_ovr_cnn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7hv5ABDHUI4"
      },
      "source": [
        "Add a markdown interpretation comparing CNN vs the best classical model:\n",
        "\n",
        "Accuracy and macro-precision differences\n",
        "\n",
        "CNN’s ability to capture spatial structure vs flattened features\n",
        "\n",
        "Optional: confusion matrix for CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-2q5RDQHTzy"
      },
      "outputs": [],
      "source": [
        "cm_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm_cnn, annot=False, cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix — CNN\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "print(classification_report(y_test, y_pred_cnn, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4PPyQTHTpX"
      },
      "source": [
        "# 5. Pick Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5iJS4aJHThB"
      },
      "outputs": [],
      "source": [
        "# Consolidate with CNN metrics\n",
        "row_cnn = {\"model\":\"CNN\", \"acc\": float(test_acc), \"prec_macro\": float(prec_macro_cnn), \"auc_ovr\": float(auc_ovr_cnn)}\n",
        "df_all = pd.concat([df_results, pd.DataFrame([row_cnn])]).sort_values(by=\"acc\", ascending=False)\n",
        "df_all\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THJpX_PWHTYB"
      },
      "source": [
        "Add markdown:\n",
        "\n",
        "State the best model (likely CNN by accuracy and AUC).\n",
        "\n",
        "Briefly justify selection and note any trade-offs (training time vs performance).\n",
        "\n",
        "If the classical model somehow wins (rare), proceed with that instead for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMKS2VpPHzrK"
      },
      "source": [
        "# 6. Task 2: Predict On Your Own 10 Images\n",
        "Instructions:\n",
        "\n",
        "Take 10 square photos (one per class if possible).\n",
        "\n",
        "Save as PNG/JPG in a folder.\n",
        "\n",
        "The pipeline: load → convert to grayscale → resize to 28x28 → normalize → shape to (28,28,1) → batch predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-aVCT5aHTQG"
      },
      "outputs": [],
      "source": [
        "# Path with 10 images\n",
        "user_img_dir = \"YOUR_10_IMAGES_FOLDER\"  # e.g., \"my_fashion_photos\"\n",
        "paths = sorted(glob.glob(os.path.join(user_img_dir, \"*.*\")))\n",
        "assert len(paths) >= 10, f\"Found {len(paths)} images, need at least 10.\"\n",
        "\n",
        "def load_and_prepare_image(p, target=(28,28)):\n",
        "    img = Image.open(p).convert(\"L\")   # grayscale\n",
        "    img = img.resize(target)           # ensure (28,28)\n",
        "    arr = np.array(img, dtype=\"float32\")/255.0\n",
        "    return arr\n",
        "\n",
        "user_imgs = [load_and_prepare_image(p) for p in paths[:10]]\n",
        "user_stack_cnn = np.stack(user_imgs)[..., np.newaxis]  # (N,28,28,1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbfzIJFvHTHF"
      },
      "source": [
        "Visualize side-by-side:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5QHkJ4UHS-Z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "for i, (p, arr) in enumerate(zip(paths[:10], user_imgs)):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(arr, cmap='binary')\n",
        "    plt.title(os.path.basename(p)[:12], fontsize=8)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzAoByAYHSy-"
      },
      "source": [
        "Predict with the best model (choose CNN if it won):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw8LqODSH-MR"
      },
      "outputs": [],
      "source": [
        "use_cnn = df_all.iloc[0][\"model\"] == \"CNN\"\n",
        "\n",
        "if use_cnn:\n",
        "    probs = cnn.predict(user_stack_cnn, verbose=2)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "else:\n",
        "    # If a classical model won:\n",
        "    user_stack_flat = user_stack_cnn.reshape(len(user_imgs), -1)\n",
        "    best_name = df_all.iloc[0][\"model\"]\n",
        "    best_clf = {\n",
        "        \"LogisticRegression\": best_lr,\n",
        "        \"SVM-Linear\": best_svm_lin,\n",
        "        \"SVM-RBF\": best_svm_rbf,\n",
        "        \"RandomForest\": rf\n",
        "    }[best_name]\n",
        "    preds = best_clf.predict(user_stack_flat)\n",
        "\n",
        "pred_labels = [class_names[i] for i in preds]\n",
        "pred_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7peOItE_IBE6"
      },
      "source": [
        "If you have ground-truth labels for your images (optional), compute accuracy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdJXSms8IAWj"
      },
      "outputs": [],
      "source": [
        "# Optional: set your true labels if known (list of 10 strings matching class_names)\n",
        "# Example: y_true_names = ['Sneaker','Bag',...]\n",
        "y_true_names = None  # replace with actual list\n",
        "\n",
        "if y_true_names is not None:\n",
        "    true_idx = [class_names.index(n) for n in y_true_names]\n",
        "    pred_acc = accuracy_score(true_idx, preds)\n",
        "    print(\"User images accuracy:\", pred_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQHVHofMG5XC"
      },
      "source": [
        "# 7. Short Discussion and Conclusions\n",
        "Use markdown to:\n",
        "\n",
        "Summarize which model outperformed and by how much.\n",
        "\n",
        "Interpret metric differences (accuracy vs macro-precision vs AUC).\n",
        "\n",
        "Mention practical considerations (speed, simplicity, deployment).\n",
        "\n",
        "Note improvements: data augmentation, deeper CNN (BatchNorm, more epochs), regularization, or transfer learning variants.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
